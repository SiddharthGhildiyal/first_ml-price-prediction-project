# -*- coding: utf-8 -*-
"""first ml_house_price_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BxySiMz2x8kQTvyt8hcMJ4IIBM9i0BOx

**IMPORTING LIB.**
"""

import pandas as pd
import numpy as np

"""**IMPORTING FILE FROM GOOLGE COLAB**"""

from google.colab import files
dataset=files.upload()

"""**READING THE FILE**"""

data=pd.read_csv('Bengaluru_House_Data.csv')

data.head()

data.shape

data.info()

for column in data.columns:
  print(data[column].value_counts())

"""**CHECKING FOR NULL VALUES IN COLUMNS**"""

data.isna().sum()

"""**DELETING THE COLUMNS WITH MOST NUMBER OF NULL VALUES**"""

data.drop(columns=['society','balcony','area_type','availability'],inplace=True)

data.describe()

data.info()

data['location'].value_counts()

"""**REPLACING THE NULL VALUES WITH MOST OCCURED VALUES**"""

data['location']=data['location'].fillna('Whitefield')

data['size'].value_counts()

data['size']=data['size'].fillna('2 BHK')

data['bath'].value_counts()

data['bath']=data['bath'].fillna(data['bath'].median())

data.info()

"""**FINDING THE OUTLIERS FOR SIZE**"""

data['BHK']=data['size'].str.split().str.get(0).astype(int)

data[data.BHK>20]

data['total_sqft'].unique()

"""**CREATING A FUNCTION TO FOR CORRECTING THE RANGE VALUE ERROR IN TOTAL SQFT**"""

def convertRange(x):
  temp=x.split('-')
  if len(temp)==2:
    return(float(temp[0])+float(temp[1]))/2
  try:
    return float(x)
  except:
    return None

data['total_sqft']=data['total_sqft'].apply(convertRange)

data.head()

"""**MAKING A NEW VARIABLE PRICE PER SQUARE FEET**"""

data['price_per_sqft']=data['price']*100000 / data['total_sqft']

data['price_per_sqft']

data.describe()

"""**APPLYING THE LAMBDA FUNCTION TO DELETE THE SPACE BETWEEN LOCATIONS**"""

data['location']=data['location'].apply(lambda x : x.strip())

"""**CREATING A NEW VARIABLE TO COUNT SAME LOCATIONS**"""

location_count=data['location'].value_counts()
location_count

location_count_lessthan_10 = location_count[location_count<=10]
location_count_lessthan_10

data['location']=data['location'].apply(lambda x: 'other' if x in location_count_lessthan_10 else x)
data['location'].value_counts()

"""**OUTLIERS DETECTION AND DELETION**"""

data.describe()

(data['total_sqft']/data['BHK']).describe()

data=data[((data['total_sqft']/data['BHK'])>=300)]
data.describe()

data.price_per_sqft.describe()

data.shape

"""**REMOVING THE OUTLIERS**"""

def remove_outliers_sqft(df):
  df_output =pd.DataFrame()
  for key,subdf in df.groupby('location'):#grouping by loxation
    m= np.mean(subdf.price_per_sqft)#mean 
    st= np.std(subdf.price_per_sqft)#standard deviation

    gen_df =subdf[(subdf.price_per_sqft > (m-st)) & (subdf.price_per_sqft <= (m+st))]
    #here i will keep only those values whichh are under the (mean +_std.deviation)
    df_output= pd.concat([df_output,gen_df],ignore_index=True)
  return df_output 
data= remove_outliers_sqft(data)#at last store it in data 
data.describe()

#above we can see changes

def bhk_outlier_remover(df):
  #in above we filter the sqft data/ now we will fiter the outlier in the bhhk 
  exclude_indices =np.array([])
  for location,location_df in df.groupby('location'):
    bhk_stats={}# 
    for bhk,bhk_df in location_df.groupby('BHK'):
      bhk_stats[bhk] ={
          'mean': np.mean(bhk_df.price_per_sqft),
          'std': np.std(bhk_df.price_per_sqft),
          'count': bhk_df.shape[0]
      }
    for bhk, bhk_df in location_df.groupby('BHK'):
      stats= bhk_stats.get(bhk-1)
      if stats and stats['count']>5:
        exclude_indices=np.append(exclude_indices,bhk_df[bhk_df.price_per_sqft < (stats['mean'])].index.values) 
  return df.drop(exclude_indices,axis='index')

data=bhk_outlier_remover(data)
data

data.drop(columns=['size','price_per_sqft'],inplace=True)

"""**CLEANED DATA**"""

data.head()

data.to_csv("Cleaned_data.csv")

x=data.drop(columns=['price'])
y=data['price']

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression,Lasso,Ridge
from sklearn.preprocessing import OneHotEncoder,StandardScaler
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline
from sklearn.metrics import r2_score

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)

"""**APPLYING LINEAR REGRESSION**"""

#i implied onehot encoder just on loaction because it was only coulm that can be categorizzed
column_trans=make_column_transformer((OneHotEncoder(sparse=False),['location']), remainder = 'passthrough')

scaler=StandardScaler(with_mean=False)#scaling

lr=LinearRegression(normalize=True)

pipe=make_pipeline(column_trans,scaler,lr)

pipe.fit(x_train,y_train)

y_pred_lr = pipe.predict(x_test)
r2_score(y_test,y_pred_lr)

"""**APPLYING LASSO**"""

lasso=Lasso()

pipe=make_pipeline(column_trans,scaler,lasso)

pipe.fit(x_train,y_train)

y_pred_lasso = pipe.predict(x_test)
r2_score(y_test,y_pred_lasso)

"""**APPLYING RIDGE**"""

ridge=Ridge()

pipe=make_pipeline(column_trans,scaler,ridge)

pipe.fit(x_train,y_train)

y_pred_ridge = pipe.predict(x_test)
r2_score(y_test,y_pred_ridge)

#import pickle